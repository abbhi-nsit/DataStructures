system design
https://www.youtube.com/playlist?list=PLMCXHnjXnTnvo6alSjVkgxV-VH6EPyvoX

https://www.nginx.com/blog/introduction-to-microservices/

https://microservices.io/

https://www.careercup.com/page?pid=software-design-interview-questions

https://www.educative.io/collection/page/5668639101419520/5649050225344512/5741031244955648

Introduction to NoSQL - Martin Fowler
https://www.youtube.com/watch?v=qI_g07C_Q5I

Uber design
https://www.quora.com/What-is-Ubers-server-architecture

Redis Use cases
http://oldblog.antirez.com/post/take-advantage-of-redis-adding-it-to-your-stack.html

How uber rebuilt their software
https://www.youtube.com/watch?v=vujVmugFsKc

===============================================================

Load Balancer			-- Nginx
Gateway					-- service in any language
Heart beat/ Notifier 	-- spring Actuator

Database 				-- nosql(cassandra, dynamodb), rdbms (mysql)
Memory cache 			-- Redis (memory cache, cache with persistence, pub-sub)
Message queue 			-- kafka (message queue, pub-sub, partitioning, consumer group)

Geo spatial queries		-- Google S2 Geometry, Redis GEOPOS, Mongodb geo-spatial
Search in reverse index	-- elasticSearch, lucene

===============================================================

System Design :

->gateway service
->messaging queue
->load balancer
->considering fail overs

servers should never fail
should have multiple copies of data for failovers
Applying multiple layers or caches at different level should result in keeping data consistent
distributing load fairly
heavy loads of request should be handled properly

===============================================================

=>Horizontal vs Vertical Scaling

1) Horizontal - Load balancing required
 vertical -- NA
 
2) Horizontal - Resilient to single point of failure
   Vertical  -  Single point of failure
   
3) Horizontal -  n/w calls from one service to another service (RPC)
   Vertical   - Inter process communication , faster
   
4) Horizontal - chances of data inconsistency, 
				data travels from one servive to another in a single request
				non atomic
   Vertical  - data consistent , atomic
   
5) Horizontal - Scales well with increase in number of request
   Vertical  -  Hardware limit


===============================================================

=>Load balancing and Consistent Hashing

If we huge number of request and N number of servers to handle those request
then we need a load balancer and also want it handle the request fairly equally to all server nodes
one way to do this is to use a hashing function 

problem will come when a new server will be added in system and 
hashing will redirect request to some different server nodes
what will happen if these nodes have their internal caches for request
** It also ensures that single request is not served to multiple nodes, avoid duplication

while performing consistent hashing in load balancing, we need to consider below factors :
1) server added
2) server removed/crashed

load should be balanced fairly and there should be as minimum change of request as possible

for this we take a ring of numbers 0--(M-1)
we take hash of servers
we do hash of request ids
and divide servers on the ring on equal distance

request will hit the server that is nearer to its clock wise location in the ring


===============================================================

=> Messaging Queue
(see pics)

Asynchronous scalable solutions
	->dont wait user to send response
	->start an asynchronous process and put your task in a Queue
some other system will pick task from queue 

What if system handling queue fails	
	-> we can persist that state in DB
	
Let say we have N servers that equally recieve task from queue as Consumers
So we need a persistence layer that will store task ids and their respective server ids

We also require a Notifier server which will check the state of server after every 20/30 sec
A load balancer will also be required here to fairly distribute load 
and to avoid duplicate request by consistent hashing

if one server gets down, notifier will transfer unprocessed task to active servers

This whole process of maintaing task in queue, processing them by server
and having notifier and load balancer is called Message/Task Queue.


===============================================================

=>Single point of failure
 whole system fails when one server or machine gets down

	-> adding nodes as server
		-> for multiple nodes we should have load balancer
			->load balancer should be more than one as for single load balancer may be a point of failure
				these load balancer will also act as gateways
				multiple IP addresses are mapped with multiple gateways of single domain
				
	-> Adding replicas for fail over
		they can master/slave or master/master
		
	-> Database layer has multiple instances, so to handle proper routing of DB calls
		there may be some kind of coordinator at DB level
		these coordinators can also be more than one in count as in case of load balancer
		

===============================================================

Anti patterns
=> Using Database as Message Queues
(see pics)

To implement Database as message queue, one server will insert data in DB
and other servers will poll data from that DB at a regular interval

Producer  ---Insert-->	Database	<---Poll---  Consumers

Database cannot push notification to other servers.
This is a way to implement message queue.(Asynchronous communication b/w different servers)
This is considered as an Anti pattern

Problems
->Polling Database at short time interval will increase load on it.
->Polling Database at long time interval will decrease response time.

*** A database can be optimized either for Read or for Write , but not both.

->Also what if a lot of messages are sent between servers.
  this will make a lot old data that has no use.
  We have delete it via a cron job or purge process
  
->We also have to do updates to rows which are not in current state,
  that will result in more load on the DB
  
-> Sacalabity problem :
	If we need to add new nodes/servers to the system to Scale,
	the DB will have more load to handle
	
Message queue solves these problems :
	-> they dont require any pull, They push the messages
		this solves polling time problem
	-> Efficient case for Read and Write operations
	-> Easy to scale and add new nodes, as nodes only need to register with queue
	
Producer  ---Push messages-->   Queue   ---Push--->  Consumer

This anti pattern will work when system is small.
i.e. 
if number of writes are small
and high number of reads can be optimized

===============================================================

=>Monolith vs Microservices

Advantages of Monolithik
-> There is no remote procedural call, network time is saved
-> Easy to find and solve issues/bugs as all code and data are in cohesive nature
-> Data is always in a consistent state.
	All ACID properties are followed here.


Disadvantages of Monolithik
-> Difficult to understand for a new developer in team, as he has to understand whole application
-> There is a lot coupling and no cohesion in application
-> For every small change or any small bug fix in application, whole server needs to be restarted
	it makes all services down even if they are not related to the issue or fix
-> Single point of failover, if one server is down whole application is not working

	
Advantages of Microservices
-> More cohesion in code and modules are decoupled 
-> Easy to work for new developer in team, as he has to understand a small part of whole bussiness
-> if one node is down , other nodes are still working.
	i.e. Partial running application is still visible to user
	Easy to handle fail overs
-> Easy to scale, add or remove server nodes at any time
	you do not need any service anymore, you take it down without effecting any other service
	
	
Disadvantages of Microservices
-> There are lot configuration things like, logging, property configurations
	that need to be done for every service 
-> If any issue/bug comes ,
	it will be a difficult task to find the actual root cause in a chain of service calls
-> you need to consider network call time
-> You also need to consider ACID properties of data if any node fails
	Any failure of server nodes should rollback all the actions
	and keep data in a Atomic, Consistent, Integrated and Durable state

	

**If one service always recieve request from another single server and not from any other node
  then these two services can be merged into single node 
  this will save network latency in remote procedural call


===============================================================

=>Publish Subscribe vs. Request Response

Client  ---Request--->  S0 server(DB)    ---Request--->    S1 server(DB)	---Request--->		S3 server  
							|									|
							|request							|Request
							|									|
						S2 server 							S4 server
						
client send request to S0
S0 sends request to S1 and S2 and wait for thier responses
S1 again sends a request to S3 and S4

S0 and S1 can have a database to store request and response data


Problems with this Design
-> This is a synchronous system, where S0 has to wait for response of S1 and S2
    S2 in tern has to wait for S3 and S4
	long waiting time for client
-> if S3 or S4 fails or gets down for some time, S1 and S0 will be blocked
-> S1 will update some state of request in its own DB
  and if blocked servers comes after some time, then servers will have inconsistence data
  They have to rollback state properly
  

Solution :
We can use publisher subscriber model
eg: Kafka, RabbitMQ

Advantages of publisher subscriber model
-> Decoupling , fire and forget
	no need to take back response
-> Easy to scale, easy to add or remove servers
-> message queue will handle fail overs


Disadvantages of publisher subscriber model
-> Cannot send instant response
-> Difficult to maintain ACID properties of Data, 
	like banking domain data, where consistency matters the most


===============================================================

=> Event Driven architecture (EDA)

Git,smalltalk is using EDA
React
Nodejs
Gaming servers
Sagas uses it in microservices system
	(events are fired and rollbacked with servers storing cached data)


In Event driven design, every service sending or recieving data
must have its own database to save event
These events can a state of an object any time t
So services need to store data of themselves and other services

Event bus is there to store the events and transfer then to appropriate services

Advantages :
-> high availability, but it causes less consistency
-> storing log of events
-> Easy rollback to any event or object state at time t
-> Easy to test/debug issues with events
-> Transactional gaurenties with micro services
-> since we have state in the event, we have an audit log feature available

Disadvantages :
-> Not applicable for Gateways, like sending an email
-> control over actual client request/response
-> We are posting every change of an object to event bus
   but that can be a security issue
   there may be some data that should not be exposed to other services
-> Difficult to understand
-> Difficult to migrate to some other design 


How to manage event history
-> replay from start
-> take diffs
-> Undo
	-> but some operations cannot be undone, like sending a mail

Compaction of events is also done to keep a final state, like end of the day/week

===============================================================

design twitter along with use cases
design tinder

Tinder :

->User profile
->users images

images can be stored in file system, rather than on DB
DB -- blob
file system -- cheaper , faster, CDN support, static files can be easily published in container
				files can also be stored in DFS

User_id, image_id, image_url

** Image can be stored on profile service itself, or they can be stored in separate service
	Image service, it can have its own personalized database.
	In future if any other service requires image, this way would decrease load from profile service also.
	And all features would be in a decoupled state.

Now user need to have login functionality
Authentication of user for every request

There could be a Person service that does registration of user and stores it username and password.
This service sends access token to the client for next request, as Http is stateless.
There could also be some 2 step authentication, for example :
	sending confirmation mail to user

** There may be multiple request by user to access application GET/POST
	Every time those request need to be authenticated
	by person service or any other service.
	To avoid this duplication, we can make a Gateway just for authentication 
	This Gateway talks to Person service and checks if user is authenticated or not.
	
client ----->   Gateway   --------->  person service
				|	|						|
				|	|						|
				|	<------------<-----------
				|
			Any other service
			
-> Now user can update his profile by uploading pics and updating status

-> Chat

for chat we cannot use HTTP protocol
we have to use XMTP/SMTP
	simple message transfer protocol
	XML Smtp
	
here we require, a web socket connection which connects user to server
or TCP connection
We need to store these connections in a database
There could be a different service for maintaining these connections against User ids
different from authentication gateway.

-> Match and swipe left/right info

For fast accessing these, infomation can be stored in client mobile itself
But it also need to have secured back up at server
if user uninstalls mobile app and again installs it, data will be downloaded from server.

A matcher service can be created to store match combinations for all users.
user1_id , user2_id

-> when user start chat with another user, it first checks at authentication gateway
	then it checks if user1 is matched with user2 at Matcher service
	then it sends data via Session service

-> Where to store chat :
	In profile service itself or there could be some Chat Service,
	with user1 and user2 Ids
	chat content and their time
	
-> Recomendations
	below factors can decide :
	age, gender, location
	
	we can use indexes to get fast recomendations
	but avoid making all columns as index
	query will pick only one index at a time, apply binary search on that column 
	and then use binary search on another column with filtered data.
	So use index appropriatly
	
*** Recomendation Database can use a Distributed database like Cassandra Or Amazon Dynamo
*** You can also use Sharding or horizontal Partitioning for fast access
	To avoid single point of failure, you can use master slave architecture (replication)

-> How sharding will help here ?
	sharding of data can be done on the basis of location of user
	that will help us to search near by clients easily
	
All these things can be stored in a separate service as Recomendation
Service can store 
user_id, current_location

user can poll its current_location and may be updated after every fix interval of time.

===============================================================

CAP theorem :
https://www.youtube.com/watch?v=hUd_9FENShA

https://www.youtube.com/watch?v=umWABit-wbk
https://www.quora.com/What-are-some-of-the-best-answers-to-the-question-How-would-you-design-Twitter-in-a-system-design-interview


===============================================================

Design problems:

Twitter
Tinder
Uber
Foodpanda
Times point
Rate Limiter


===============================================================

when to use no sql database
	-> https://www.slideshare.net/fabiofumarola1/data-modeling-for-nosql-12

When to use mongodb

=>Cassandra use cases :

https://blog.pythian.com/cassandra-use-cases/
https://blog.pythian.com/cassandra-time-series-database/
https://www.datastax.com/2014/06/what-are-people-using-cassandra-for
